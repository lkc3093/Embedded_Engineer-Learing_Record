# **ML**
1. *relu* 优点
    * 当 *loss* 过大或者过小，*sigmoid*，*tanh* 的导数接近于0，*relu* 为非饱和激活函数不存在这种现象

2. resnet优点
   * 防止梯度消失

3. 数据预处理

4. *Batch normalization* 用于将数据的分布重整，标准化；数据变成正态分布，有效减少梯度消失

5. 动态调节学习率

6. *FSMN* 与 *RNN* 不同的是，每一层都保存的是前面时刻的feature，然后进行降维，输入到下一时刻的隐藏层中
  * *CFSMN* 将前一刻的feature降维了，减少参数；并只输出记忆模块参数
  * *DFSMN* 增加了跳跃输入，类似于resnet

## **算法优化**
* 深度可分离卷积，每个通道单独卷积，然后多个通道逐点点积
  * *MobileNet*
* 算子融合，前一个计算图的结果是后一个计算图的输入，可以融合，减少数据的 *load*，*store* 的操作
  * 可以通过 *tvm* 前端来实现
* 通过加 *L2* 正则，将输入的权重稀疏化，节省内存
  * 稀疏矩阵可以只访问非0值部分，减少指令读取的执行
* 向量指令加速
  * 内联，减少函数跳转，和堆栈开辟
  * 指令并行，无数据冲突的指令流水线执行
  * VILW，相当于多发射，指令槽
* 异构多核
  * 完成会报中断，类似于线程同步
* 量化
  * 定点数，int8
  * tensorflow训练中量化
  * 非对称量化更好

## RTOS
* 线程切换类似于中断中的上下文保护
* 互斥量是对共享内存(全局变量之类)的保护
* sizeof 指针是4个字节
*  1. 结构体变量的首地址能够被其最宽基本类型成员的大小所整除；
   1. 结构体每个成员相对结构体首地址的偏移量(offset)都是成员大小的整数倍，如有需编译器会在成员之间加上填充字节(internal adding)；
   2. 结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要编译器会在最末一个成员之后加上填充字节{trailing padding}。

## OPENCL

* 执行模式有任务并行和数据并行
* 要想使用多个核心，通过`get_global_id` 来嵌入使用
* **Work-item**（工作项）：**Work-item**与**CUDA Threads**是一样的，是最小的执行单元。每次一个Kernel开始执行，很多（程序员定义数量）的**Work-item**就开始运行，每个都执行同样的代码。每个**work-item**有一个**ID**，这个ID在kernel中是可以访问的，每个运行在**work-item**上的kernel通过这个ID来找出**work-item**需要处理的数据。
* 可以使用`constant` 来将数据放入常量存储区
* 存储器模式是软件定义的，而非单纯硬件实现
* 